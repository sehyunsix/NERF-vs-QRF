{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum\n",
    "import pennylane as qml\n",
    "\n",
    "# Numericlal\n",
    "import math\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Trainer\n",
    "from trainer import trainer\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemma1:\n",
    "    '''\n",
    "        QAF 논문 Lemma 1을 구현하기 위한 class\n",
    "    '''\n",
    "    def __init__(self, w, x, b):\n",
    "        '''\n",
    "            w(list) : list for weight\n",
    "            x(list) : list for x(input) \n",
    "            b(float) : float value of bias\n",
    "        '''\n",
    "        # list Initiallize\n",
    "        self.w_list = w\n",
    "        self.x_list = x\n",
    "        self.b = b\n",
    "\n",
    "        # vector Initiallize\n",
    "        self.x = np.array(self.x_list)\n",
    "        self.w = np.array(self.w_list)\n",
    "\n",
    "        # lengths Calculate\n",
    "        self.N_in = len(x)\n",
    "        self.N = int(2 ** (np.ceil(np.log2(self.N_in + 3))))\n",
    "        self.n = int(np.log2(self.N))\n",
    "\n",
    "        # A_x, A_wb Calculate\n",
    "        self.A_x  = np.sqrt(self.N_in - (self.x @ self.x))\n",
    "        self.A_wb = np.sqrt(self.N_in + 1 - (self.w @ self.w + self.b * self.b))\n",
    "\n",
    "        # v_x, v_wb\n",
    "        self.v_x  = [self.A_x]  + self.x_list + [1.0]       + ([0.0] * (self.N - self.N_in - 2))\n",
    "        self.v_wb = [0.0]       + self.w_list + [self.b]    + ([0.0] * (self.N - self.N_in - 3)) + [self.A_wb]\n",
    "\n",
    "        # device initiallize\n",
    "        # n : num_qubit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=self.n)\n",
    "\n",
    "    def norm(self, vec):\n",
    "        return np.linalg.norm(vec)\n",
    "\n",
    "    def u(self, vec):\n",
    "        qml.AmplitudeEmbedding(vec, wires=range(self.n), normalize=True)\n",
    "\n",
    "    def lemma1(self, chk=False):\n",
    "        @qml.qnode(device=self.dev)\n",
    "        def inner_lemma1():\n",
    "            # U_x, i.e. small_u(v_x)\n",
    "            self.u(self.v_x)\n",
    "\n",
    "            # U_wb, i.e. small_u(v_wb)^†, Pauli-X for each qubit\n",
    "            qml.adjoint(self.u)(self.v_wb)\n",
    "            for i in range(self.n):\n",
    "                qml.PauliX(wires=i)\n",
    "            \n",
    "            return qml.state()\n",
    "        if chk:\n",
    "            print(qml.draw_mpl(inner_lemma1)())\n",
    "        return inner_lemma1()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 1, Corollary 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theorem1:\n",
    "    '''\n",
    "        QAF 논문 Theorem 1을 구현하기 위한 class\n",
    "    '''\n",
    "    def __init__(self, w, x, b, d, l = 0):\n",
    "        '''\n",
    "            w(list)     : list for weight\n",
    "            x(list)     : list for x(input) \n",
    "            b(float)    : float value of bias\n",
    "            d(int)      : degree for Taylor (polynomial) Expansion\n",
    "        '''\n",
    "        # list Initiallize\n",
    "        self.w_list = w\n",
    "        self.x_list = x\n",
    "        self.b = b\n",
    "        self.d = d\n",
    "        self.l = l\n",
    "\n",
    "        # vector Initiallize\n",
    "        self.x = np.array(self.x_list)\n",
    "        self.w = np.array(self.w_list)\n",
    "\n",
    "        # lengths Calculate\n",
    "        self.N_in = len(x)\n",
    "        self.N = int(2 ** (np.ceil(np.log2(self.N_in + 3))))\n",
    "        self.n = int(np.log2(self.N))\n",
    "\n",
    "        # A_x, A_wb Calculate\n",
    "        self.A_x  = np.sqrt(self.N_in - (self.x @ self.x))\n",
    "        self.A_wb = np.sqrt(self.N_in + 1 - (self.w @ self.w + self.b * self.b))\n",
    "\n",
    "        # v_x, v_wb\n",
    "        self.v_x  = [self.A_x]  + self.x_list + [1.0]       + ([0.0] * (self.N - self.N_in - 2))\n",
    "        self.v_wb = [0.0]       + self.w_list + [self.b]    + ([0.0] * (self.N - self.N_in - 3)) + [self.A_wb]\n",
    "\n",
    "        # device initiallize\n",
    "        # n : num_qubit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=(self.n + self.d + self.l))\n",
    "\n",
    "    def U_z(self):\n",
    "        qml.AmplitudeEmbedding(self.v_x, wires=range(self.n), normalize=True)\n",
    "        qml.adjoint(qml.AmplitudeEmbedding)(self.v_wb, wires=range(self.n), normalize=True)\n",
    "        for i in range(self.n):\n",
    "            qml.PauliX(wires=i)\n",
    "\n",
    "    def V(self, m):\n",
    "        a_m = self.n + m\n",
    "\n",
    "        # Controlled-Hadamard for (control, target) : (q register, a_m)\n",
    "        qml.ctrl(qml.Hadamard, control=range(self.n))(wires=a_m)\n",
    "        \n",
    "        # CNOT for (control, target) : (a_m, q register)\n",
    "        for i in range(self.n):\n",
    "            qml.CNOT(wires=[a_m, i])\n",
    "        \n",
    "        # Controlled-U(x, w, b) for : (a_m, q register)\n",
    "        qml.ctrl(self.U_z, control=a_m)()\n",
    "\n",
    "    def outer_theorem1(self):\n",
    "        '''\n",
    "            Pauli-X 후 S_V(V_0, V_1, ... , V_{d-1})\n",
    "        '''\n",
    "        # Pauli-X for each qubit of q register\n",
    "        for i in range(self.n):\n",
    "            qml.PauliX(wires=i)\n",
    "        \n",
    "        # V_m for each m in (0, ... , d - 1)\n",
    "        for m in range(self.d):\n",
    "            self.V(m)\n",
    "\n",
    "    def theorem1(self, chk=False):\n",
    "        '''\n",
    "            Theorem 1의 state |psi_z^d> 를 생성해서, state vector를 return\n",
    "        '''\n",
    "        @qml.qnode(device=self.dev)\n",
    "        def inner_theorem1():\n",
    "            self.outer_theorem1()\n",
    "            return qml.state()\n",
    "        \n",
    "        if chk:\n",
    "            print(qml.draw_mpl(inner_theorem1)())\n",
    "        return inner_theorem1()\n",
    "    \n",
    "    def corollary1(self, k):\n",
    "        '''\n",
    "            k를 input으로 받아, |N-1>(q)|2^k - 1>(a) state에 대한 amplitude를 return\n",
    "        '''\n",
    "        result = self.theorem1()\n",
    "        bitstring = ('1' * self.n) + ('0' * (self.d - k)) + ('1' * k)\n",
    "        index = int(bitstring, 2)\n",
    "        return result[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x_tensor\n",
    "# print(x_tensor)\n",
    "# N_in = len(x_tensor)\n",
    "# A_x  = torch.sqrt(torch.tensor([N_in - (x @ x)]))\n",
    "# A_wb = torch.sqrt(N_in + 1 - (x @ x))\n",
    "# print(A_x)\n",
    "# my_tensors = (x_tensor, torch.tensor([N_in]), A_x)\n",
    "# torch.cat(my_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(nn.Module):\n",
    "    '''\n",
    "        qaf_layer, 즉 n-to-1 perceptron(wx+b)에서, w가 잘 업데이트 되는지 확인하기 위한 클래스\n",
    "    '''\n",
    "    def __init__(self, input_size):\n",
    "        '''\n",
    "            input_size(int) : w와 x의 size -> N_in\n",
    "        '''\n",
    "        super(test, self).__init__()\n",
    "\n",
    "        self.weights = nn.Parameter(torch.rand(input_size, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.activation = 'sin(z)'\n",
    "    \n",
    "    def forward(self, dim=4):\n",
    "        N_in = len(self.weights) # torch.tensor([len(self.weights)])\n",
    "        N = int(2 ** (np.ceil(np.log2(N_in + 3))))\n",
    "        result  = torch.sqrt(torch.tensor(N_in - (self.weights @ self.weights)))\n",
    "\n",
    "        return result # @ temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/m77q01ls5n12fr3t97v33_lh0000gn/T/ipykernel_10314/3065268859.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result  = torch.sqrt(torch.tensor(N_in - (self.weights @ self.weights)))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m res \u001b[38;5;241m=\u001b[39m test1()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(test1\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mgrad)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "test1 = test(4)\n",
    "res = test1()\n",
    "print(res)\n",
    "res.backward()\n",
    "print(test1.weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0.4111, 0.4636, 0.3183, 0.7571], requires_grad=True), Parameter containing:\n",
      "tensor([0.3973], requires_grad=True)]\n",
      "tensor([1.7151], grad_fn=<SqrtBackward0>)\n",
      "None\n",
      "[Parameter containing:\n",
      "tensor([0.4111, 0.4636, 0.3183, 0.7571], requires_grad=True), Parameter containing:\n",
      "tensor([0.3973], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "test1 = test(4)\n",
    "print(list(test1.parameters()))\n",
    "op1 = optim.Adam(test1.parameters(), lr=0.01)\n",
    "# op1.zero_grad()\n",
    "res = test1()\n",
    "print(res)\n",
    "res.backward()\n",
    "print(test1.weights.grad)\n",
    "op1.step()\n",
    "print(list(test1.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theorem1: # _for_torch:\n",
    "    '''\n",
    "        QAF 논문 Theorem 1을 구현하기 위한 class\n",
    "    '''\n",
    "    def __init__(self, w, x, b, d, l = 0):\n",
    "        '''\n",
    "            w(torch.tensor([]))     : list for weight\n",
    "            x(torch.tensor([]))     : list for x(input) \n",
    "            b(torch.tensor([]))    : float value of bias\n",
    "            d(int)      : degree for Taylor (polynomial) Expansion\n",
    "        '''\n",
    "\n",
    "        # print('Before list Initiallize Init')\n",
    "        # list Initiallize\n",
    "        self.w = w\n",
    "        self.x = x\n",
    "        self.b = b\n",
    "        self.d = d\n",
    "        self.l = l\n",
    "\n",
    "        # # vector Initiallize\n",
    "        # self.x = np.array(self.x_list)\n",
    "        # self.w = np.array(self.w_list)\n",
    "\n",
    "        # print('Before lengths Calculate Init')        \n",
    "        # lengths Calculate\n",
    "        self.N_in = len(self.x)\n",
    "        self.N = int(2 ** (np.ceil(np.log2(self.N_in + 3))))\n",
    "        self.n = int(np.log2(self.N))\n",
    "\n",
    "        # print('Before A_x, A_wb Calculate Init')           \n",
    "        # A_x, A_wb Calculate\n",
    "        self.A_x  = torch.sqrt(torch.tensor([self.N_in - (self.x @ self.x)]))\n",
    "        self.A_wb = torch.sqrt(torch.tensor([self.N_in + 1 - (self.w @ self.w + self.b * self.b)]))\n",
    "\n",
    "        # print('Before v_x, v_wb Init')           \n",
    "        # v_x, v_wb\n",
    "        self.v_x    = torch.cat((self.A_x,            self.x, torch.tensor([1.0]), torch.tensor([0.0] * (self.N - self.N_in - 2))))               # [self.A_x]  + self.x_list + [1.0]       + ([0.0] * (self.N - self.N_in - 2))\n",
    "        self.v_wb   = torch.cat((torch.tensor([0.0]), self.w, self.b             , torch.tensor([0.0] * (self.N - self.N_in - 3)), self.A_wb))   # [0.0]       + self.w_list + [self.b]    + ([0.0] * (self.N - self.N_in - 3)) + [self.A_wb]\n",
    "\n",
    "        # device initiallize\n",
    "        # n : num_qubit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=(self.n + self.d + self.l))\n",
    "\n",
    "    def U_z(self):\n",
    "        qml.AmplitudeEmbedding(self.v_x, wires=range(self.n), normalize=True)\n",
    "        qml.adjoint(qml.AmplitudeEmbedding)(self.v_wb, wires=range(self.n), normalize=True)\n",
    "        for i in range(self.n):\n",
    "            qml.PauliX(wires=i)\n",
    "\n",
    "    def V(self, m):\n",
    "        a_m = self.n + m\n",
    "\n",
    "        # Controlled-Hadamard for (control, target) : (q register, a_m)\n",
    "        qml.ctrl(qml.Hadamard, control=range(self.n))(wires=a_m)\n",
    "        \n",
    "        # CNOT for (control, target) : (a_m, q register)\n",
    "        for i in range(self.n):\n",
    "            qml.CNOT(wires=[a_m, i])\n",
    "        \n",
    "        # Controlled-U(x, w, b) for : (a_m, q register)\n",
    "        qml.ctrl(self.U_z, control=a_m)()\n",
    "\n",
    "    def outer_theorem1(self):\n",
    "        '''\n",
    "            Pauli-X 후 S_V(V_0, V_1, ... , V_{d-1})\n",
    "        '''\n",
    "        # Pauli-X for each qubit of q register\n",
    "        for i in range(self.n):\n",
    "            qml.PauliX(wires=i)\n",
    "        \n",
    "        # V_m for each m in (0, ... , d - 1)\n",
    "        for m in range(self.d):\n",
    "            self.V(m)\n",
    "\n",
    "    def theorem1(self, chk=False):\n",
    "        '''\n",
    "            Theorem 1의 state |psi_z^d> 를 생성해서, state vector를 return\n",
    "        '''\n",
    "        @qml.qnode(device=self.dev, interface=\"torch\")\n",
    "        def inner_theorem1():\n",
    "            self.outer_theorem1()\n",
    "            return qml.state()\n",
    "        \n",
    "        if chk:\n",
    "            print(qml.draw_mpl(inner_theorem1)())\n",
    "        return inner_theorem1()\n",
    "    \n",
    "    def corollary1(self, k):\n",
    "        '''\n",
    "            k를 input으로 받아, |N-1>(q)|2^k - 1>(a) state에 대한 amplitude를 return\n",
    "        '''\n",
    "        result = self.theorem1()\n",
    "        bitstring = ('1' * self.n) + ('0' * (self.d - k)) + ('1' * k)\n",
    "        index = int(bitstring, 2)\n",
    "        return result[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theorem2(Theorem1):\n",
    "    def __init__(self, w, x, b, d, f, l = 0):\n",
    "        '''\n",
    "            w, x, b, d : same as Thm1\n",
    "            f(str) : name of function which will be sympified\n",
    "        '''\n",
    "\n",
    "        # print('Before Thm1 Init')\n",
    "        super().__init__(w, x, b, d, l=l)\n",
    "        # print('After Thm1 Init')\n",
    "        self.f = sp.sympify(f) # target f\n",
    "        self.k = -1     # target f의 taylor expansion 중 계수가 0이 아닌 최저 차수\n",
    "        self.C_d = 1    # f_d(z)와 실제 f(z)의 factoring constant\n",
    "        self.theta_list = self.make_theta_list()\n",
    "\n",
    "\n",
    "    def taylor_series_coefficients(self):\n",
    "        # 심볼 정의\n",
    "        z = sp.symbols('z')\n",
    "        point = 0.0\n",
    "        \n",
    "        # 테일러 전개 계산\n",
    "        taylor_expansion = sp.series(self.f, z, point, self.d + 1).removeO()\n",
    "        \n",
    "        # 계수 추출\n",
    "        coeffs = [taylor_expansion.coeff(z, i) for i in range(self.d + 1)]\n",
    "        return coeffs\n",
    "        \n",
    "    def make_theta_list(self):\n",
    "        # Get Coeffs of Taylor (polynomial) Expansion of target f\n",
    "        coefficients = self.taylor_series_coefficients()\n",
    "        \n",
    "        # Update k (target f의 taylor expansion 중 계수가 0이 아닌 최저 차수)\n",
    "        for i in range(0, self.d + 1):\n",
    "            if coefficients[i] != 0:\n",
    "                self.k = i\n",
    "                break\n",
    "        \n",
    "        theta_list = [0 for _ in range(self.d)]\n",
    "        # target f = 0\n",
    "        if self.k < 0: \n",
    "            return theta_list\n",
    "        \n",
    "        # a_i = 0 for all i < k\n",
    "        for i in range(self.k):\n",
    "            theta_list[i] = -1 * math.pi / 2\n",
    "\n",
    "        # a_k Initiallization\n",
    "        theta_list[self.k] = math.atan(-1 * coefficients[self.k + 1] / coefficients[self.k])\n",
    "\n",
    "        A = 1\n",
    "        for i in range(self.k + 1, len(coefficients) - 1):\n",
    "            A *= math.cos(theta_list[i - 1])\n",
    "            theta_list[i] = math.atan(-1 * coefficients[i + 1] / coefficients[self.k] * A)\n",
    "        \n",
    "        # C_d update\n",
    "        C_d = coefficients[self.k] # a_k\n",
    "        for i in range(self.k, self.d):\n",
    "            C_d /= math.cos(theta_list[i]) # 1/cos(theta)\n",
    "        self.C_d = torch.tensor([float(C_d)])\n",
    "\n",
    "        return theta_list\n",
    "    \n",
    "    def U(self, d):\n",
    "        '''\n",
    "            U_d Unitary for S_U iteration\n",
    "        '''\n",
    "        theta_list = self.theta_list # make_theta_list()\n",
    "        for k in range(1, d):\n",
    "            a_0 = self.n\n",
    "            a_k = a_0 + k\n",
    "            qml.ctrl(qml.RY, control=a_k, control_values=0)(2 * theta_list[k - 1], wires=a_0)\n",
    "            qml.CNOT(wires=[a_0, a_k])\n",
    "    \n",
    "    def outer_theorem2(self):\n",
    "        '''\n",
    "            S_U := d register에는 U_d, q register에는 Pauli-X for each qubit\n",
    "        '''\n",
    "        # Pauli-X for each qubit of q register\n",
    "        # and S_V\n",
    "        self.outer_theorem1()\n",
    "\n",
    "        qml.Barrier()\n",
    "\n",
    "        # U_d\n",
    "        self.U(self.d)\n",
    "\n",
    "        qml.Barrier()\n",
    "\n",
    "        # Pauli-X for each qubit of q register\n",
    "        for i in range(self.n):\n",
    "            qml.PauliX(wires=i)\n",
    "\n",
    "    def theorem2(self, chk=False):\n",
    "        @qml.qnode(device=self.dev, interface=\"torch\")\n",
    "        def inner_theorem2():\n",
    "            self.outer_theorem2()\n",
    "            return qml.state()\n",
    "        if chk:\n",
    "            print(qml.draw_mpl(self.outer_theorem2)())\n",
    "        return inner_theorem2()\n",
    "\n",
    "    def corollary2(self, k):\n",
    "        '''\n",
    "            as same as col 1,\n",
    "            k를 input으로 받아, |N-1>(q)|2^k - 1>(a) state에 대한 amplitude를 return\n",
    "        '''\n",
    "        result = self.theorem2()\n",
    "        bitstring = ('0' * self.n) + ('0' * (self.d - k)) + ('1' * k)\n",
    "        index = int(bitstring, 2)\n",
    "        return result[index] * self.C_d # * C_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qaf_layer(Theorem2):\n",
    "    def __init__(self, w, x, b, d, f):\n",
    "        '''\n",
    "            w, x, b, d : same as Thm1\n",
    "            f(str) : name of function which will be sympified\n",
    "        '''\n",
    "        # print('Before Thm2 Init')\n",
    "        super().__init__(w, x, b, d, f, l = 1)\n",
    "        # print('After Thm2 Init')\n",
    "        \n",
    "        self.f = sp.sympify(f) # target f\n",
    "        self.k = -1 # target f의 taylor expansion 중 계수가 0이 아닌 최저 차수\n",
    "        self.theta_list = self.make_theta_list()\n",
    "    \n",
    "    def outer_controlled_theorem2(self):\n",
    "        l_0 = self.n + self.d # index of l register\n",
    "\n",
    "        qml.Hadamard(wires=l_0) # Hadamard for l register\n",
    "\n",
    "        qml.Barrier()\n",
    "\n",
    "        qml.ctrl(self.outer_theorem2, control=l_0)()\n",
    "\n",
    "        qml.Barrier()\n",
    "\n",
    "        qml.Hadamard(wires=l_0) # Hadamard for l register\n",
    "    \n",
    "    def controlled_theorem2(self):\n",
    "        @qml.qnode(device=self.dev, interface=\"torch\")\n",
    "        def inner_controlled_theorem2():\n",
    "            self.outer_controlled_theorem2()\n",
    "            return qml.probs()\n",
    "        return inner_controlled_theorem2()\n",
    "    \n",
    "    def amplitude_estimation(self):\n",
    "        result = self.controlled_theorem2()[0] # get P_0\n",
    "        factorized_inner_product = torch.sqrt(4 * result) - 1\n",
    "        inner_product = factorized_inner_product * (2 ** (self.d / 2))\n",
    "        return inner_product\n",
    "    \n",
    "    def activation_estimation(self):\n",
    "        result = self.amplitude_estimation()\n",
    "        return result * self.C_d\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list Initiallize\n",
    "x_tensor = torch.tensor([0.1, -0.2, -0.3, -0.4])\n",
    "w_tensor = torch.tensor([-0.8, 0.7, 0.9, 0.3])\n",
    "b = torch.tensor([0.5])\n",
    "d = 5\n",
    "f = 'sin(z)'\n",
    "\n",
    "args = [x_tensor, w_tensor, b, d, f]\n",
    "\n",
    "N_in = len(x_tensor)\n",
    "z = (np.array(x_tensor) @ np.array(x_tensor) + b) / (N_in + 1)\n",
    "\n",
    "target_w = torch.tensor([-0.8, 0.7, 0.9, 0.3])\n",
    "target_b = torch.tensor([0.5])\n",
    "# 'f(wx+b) -> f(target_w * x + target_b)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch x: torch.Size([4])\n",
      "Example batch y: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "num_data = 20000  # 총 데이터 개수\n",
    "batch_size = 1  # 배치 크기\n",
    "\n",
    "x_data = torch.rand(4, num_data)  # (20000, 1) shape로 생성\n",
    "y_data = target_w @ x_data + target_b  # sin 함수로 출력 생성 (20000, 1)\n",
    "x_data = x_data.T\n",
    "# 텐서 데이터셋 생성\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "\n",
    "# Train/Test set 분할 (80%/20% 비율)\n",
    "train_size = int(0.8 * num_data)\n",
    "test_size = num_data - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = train_dataset # DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = test_dataset # DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 배치 예시 출력\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(\"Example batch x:\", x_batch.shape)  # Expected: [128, 1]\n",
    "print(\"Example batch y:\", y_batch.shape)  # Expected: [128, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qaf_model(nn.Module):\n",
    "    '''\n",
    "        qaf_layer, 즉 n-to-1 perceptron(wx+b)에서, w가 잘 업데이트 되는지 확인하기 위한 클래스\n",
    "    '''\n",
    "    def __init__(self, input_size):\n",
    "        '''\n",
    "            input_size(int) : w와 x의 size -> N_in\n",
    "        '''\n",
    "        super(qaf_model, self).__init__()\n",
    "\n",
    "        self.weights = nn.Parameter(torch.rand(input_size, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.activation = 'sin(z)'\n",
    "    \n",
    "    def forward(self, input, dim=4):\n",
    "        q_layer = qaf_layer(w=self.weights, x=input, b=self.bias, d=dim, f=self.activation)\n",
    "        return self.\n",
    "        return q_layer.activation_estimation() # .retain_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2611, 0.4363, 0.5903, 0.1591])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    x_input = e[0]\n",
    "    break\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = qaf_model(4)\n",
    "res = q2(x_input)\n",
    "res.backward()\n",
    "q2.weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.9617, 0.8074, 0.0075, 0.2777], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0269], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = qaf_model(4)\n",
    "\n",
    "trainer1 = trainer(q2, train_loader=train_loader, test_loader=test_loader)\n",
    "\n",
    "list(q2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5566, 0.8377, 0.6795, 0.3624])\n"
     ]
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    print(e[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/homebrew/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights grad :  tensor([nan, nan, nan, nan])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "State vectors have to be of norm 1.0, vector 0 has squared norm nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ajou Univ/Curriculum/2024-2(4-1)/MathmaticalResearch/Codes/NERF-vs-QRF/QAF/trainer.py:67\u001b[0m, in \u001b[0;36mtrainer.train\u001b[0;34m(self, epochs, chk)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 67\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(pred, y)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mqaf_model.forward\u001b[0;34m(self, input, dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     16\u001b[0m     q_layer \u001b[38;5;241m=\u001b[39m qaf_layer(w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, d\u001b[38;5;241m=\u001b[39mdim, f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mqaf_layer.activation_estimation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactivation_estimation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamplitude_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_d\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mqaf_layer.amplitude_estimation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamplitude_estimation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 36\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrolled_theorem2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# get P_0\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     factorized_inner_product \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m result) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     38\u001b[0m     inner_product \u001b[38;5;241m=\u001b[39m factorized_inner_product \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mqaf_layer.controlled_theorem2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mouter_controlled_theorem2()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mprobs()\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_controlled_theorem2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/workflow/qnode.py:1020\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39mqnode_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/workflow/qnode.py:1008\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn(shots\u001b[38;5;241m=\u001b[39moverride_shots, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m old_interface \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/workflow/qnode.py:957\u001b[0m, in \u001b[0;36mQNode._execution_component\u001b[0;34m(self, args, kwargs, override_shots)\u001b[0m\n\u001b[1;32m    951\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m    952\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    953\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*argument is deprecated and will be removed in version 0.39.*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    954\u001b[0m         category\u001b[38;5;241m=\u001b[39mqml\u001b[38;5;241m.\u001b[39mPennyLaneDeprecationWarning,\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m--> 957\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/workflow/execution.py:653\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, inner_transform, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp, mcm_config)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_batch_transform:\n\u001b[1;32m    648\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice batch transforms cannot be turned off with the new device interface.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    651\u001b[0m     )\n\u001b[0;32m--> 653\u001b[0m tapes, post_processing \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_program\u001b[38;5;241m.\u001b[39mis_informative:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(tapes)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/transforms/core/transform_program.py:515\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    514\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums[i][j]\n\u001b[0;32m--> 515\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[1;32m    518\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/devices/preprocess.py:372\u001b[0m, in \u001b[0;36mdecompose\u001b[0;34m(tape, stopping_condition, stopping_condition_shots, skip_initial_state_prep, decomposer, max_expansion, name, error)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (tape,), null_postprocessing\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     new_ops \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         final_op\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations[\u001b[38;5;28mlen\u001b[39m(prep_op) :]\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m final_op \u001b[38;5;129;01min\u001b[39;00m _operator_decomposition_gen(\n\u001b[1;32m    373\u001b[0m             op,\n\u001b[1;32m    374\u001b[0m             stopping_condition,\n\u001b[1;32m    375\u001b[0m             decomposer\u001b[38;5;241m=\u001b[39mdecomposer,\n\u001b[1;32m    376\u001b[0m             max_expansion\u001b[38;5;241m=\u001b[39mmax_expansion,\n\u001b[1;32m    377\u001b[0m             name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    378\u001b[0m             error\u001b[38;5;241m=\u001b[39merror,\n\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m     ]\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReached recursion limit trying to decompose operations. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperator decomposition may have entered an infinite loop.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/devices/preprocess.py:64\u001b[0m, in \u001b[0;36m_operator_decomposition_gen\u001b[0;34m(op, acceptance_function, decomposer, max_expansion, current_depth, name, error)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         decomp \u001b[38;5;241m=\u001b[39m \u001b[43mdecomposer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m         current_depth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mDecompositionUndefinedError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/devices/preprocess.py:355\u001b[0m, in \u001b[0;36mdecompose.<locals>.decomposer\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecomposer\u001b[39m(op):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/ops/op_math/controlled.py:723\u001b[0m, in \u001b[0;36mControlled.decomposition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_decomposition(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_values):\n\u001b[0;32m--> 723\u001b[0m     decomp \u001b[38;5;241m=\u001b[39m \u001b[43m_decompose_no_control_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decomp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mDecompositionUndefinedError\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/ops/op_math/controlled.py:882\u001b[0m, in \u001b[0;36m_decompose_no_control_values\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m op\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mhas_decomposition:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m base_decomp \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(base_decomp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op\u001b[38;5;241m.\u001b[39mbase, qml\u001b[38;5;241m.\u001b[39mGlobalPhase) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(op\u001b[38;5;241m.\u001b[39mcontrol_wires) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    884\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-Controlled-GlobalPhase currently decomposes to nothing, and this will likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduce incorrect results. Consider implementing your circuit with a different set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof operations, or use a device that natively supports GlobalPhase.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    889\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/ops/op_math/adjoint.py:382\u001b[0m, in \u001b[0;36mAdjoint.decomposition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mhas_adjoint:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39madjoint()]\n\u001b[0;32m--> 382\u001b[0m base_decomp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [Adjoint(op) \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(base_decomp)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/operation.py:1337\u001b[0m, in \u001b[0;36mOperator.decomposition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecomposition\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Representation of the operator as a product of other operators.\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \n\u001b[1;32m   1328\u001b[0m \u001b[38;5;124;03m    .. math:: O = O_1 O_2 \\dots O_n\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;124;03m        list[Operator]: decomposition of the operator\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_decomposition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/ops/qubit/state_preparation.py:335\u001b[0m, in \u001b[0;36mStatePrep.compute_decomposition\u001b[0;34m(state, wires, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_decomposition\u001b[39m(state: TensorLike, wires: WiresLike, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Operator]:\n\u001b[1;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Representation of the operator as a product of other operators (static method). :\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    .. math:: O = O_1 O_2 \\dots O_n.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mMottonenStatePreparation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/capture/capture_meta.py:89\u001b[0m, in \u001b[0;36mCaptureMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enabled():\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# when tracing is enabled, we want to\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# use bind to construct the class if we want class construction to add it to the jaxpr\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_primitive_bind_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pennylane/templates/state_preparations/mottonen.py:317\u001b[0m, in \u001b[0;36mMottonenStatePreparation.__init__\u001b[0;34m(self, state_vector, wires, id)\u001b[0m\n\u001b[1;32m    315\u001b[0m         norm \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msum(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mabs(state) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mallclose(norm, \u001b[38;5;241m1.0\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m--> 317\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    318\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState vectors have to be of norm 1.0, vector \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has squared norm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m             )\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(state_vector, wires\u001b[38;5;241m=\u001b[39mwires, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: State vectors have to be of norm 1.0, vector 0 has squared norm nan"
     ]
    }
   ],
   "source": [
    "trainer1.train(chk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(q2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m q2(e[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(q2\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(q2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "q2 = qaf_model(4)\n",
    "\n",
    "for e in train_loader:\n",
    "    print(q2.weights.grad)\n",
    "    print(q2.bias.grad)\n",
    "    res = q2(e[0])\n",
    "    res.backward()\n",
    "    print(q2.weights.grad)\n",
    "    print(q2.bias.grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.7701, 0.3137, 0.5186, 0.8166], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3878], requires_grad=True)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
